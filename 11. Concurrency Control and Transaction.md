- Purpose
	- Concurrency happens when more than one thread is trying to access and modify the same resource.
	- In a system design interview, it is important to discuss what problems can arise due to concurrency issues because it may lead to unexpected behavior if not handled properly. Concurrency is a topic many candidates avoid, yet it’s a topic commonly faced in daily engineering challenges, so demonstrating competency in this area will be perceived strongly by the interviewers.
	- During the interview, if you have any data sources that can be read or modified by multiple requests, there is a potential concurrency problem. Concurrency is important because it affects the correctness and reliability of the system. If left unaddressed will lead to unhappy customers. Concurrency and transaction are important since they’re the core of some system design questions, like meeting and ticket booking systems.
- Examples
	- Design a Global Counter
		- A problem with the global counter is the read-modify-write problem. For example, imagine two threads are trying to increment x by 1, and the current value of x is 1. Both threads read x simultaneously and see that x is 1, and both increment x by 1. Each thread thinks x is now 2 and persists x as 2. Instead of 3, the final result becomes 2.
	- Ridesharing Service
		- When the interviewer asks you to design a service that matches riders with drivers, another request may also be reading from the same list of drivers when you read from the location service for available drivers. As a result, the matching service may assign the same driver to multiple riders because the matcher used the same driver list to match rides.
	- Design a Ticket Booking System
		- When the interviewer asks you to design a ticket booking system where each booker is assigned a unique seat number, you need to ensure you don’t allow multiple users to book the same seat. Otherwise this could cause issues at the event when two people show up for the same seat.
	- Design a Meeting Scheduling System
		- When the interviewer asks you to design a meeting booking system where each meeting has a from_time to to_time, you need to ensure a room doesn’t get double-booked for any of the timeslots.
- Solution
	- Single Thread
		- One way to deal with concurrency is to process the requests one by one, also known as processing things serially. By inserting the requests into some sort of queue they can be processed one by one. That way, no resources can be accessed by more than one request.
		- The advantage of this solution is the system no longer has concurrency issues. The disadvantage of this solution is potentially poor throughput, since processing things one by one can be slow. However, in an interview, you need to make sure that’s not a problem. Perhaps the QPS is very low such that it is not an issue.
	- Single Thread Micro Batch
		- Processing requests one by one may not satisfy the throughput needed for the system because for every request, you may be bounded by disk IO or some other expensive operation. One improvement would be to batch a couple of requests together and solve the problem in a batch. For example, in a ridesharing matching example, you can dispatch a couple of requests and fetch a list of driver locations and solve the matching algorithm for multiple requests and multiple drivers in the solver, so it is still effectively one thread.
		- The advantage of this solution is potentially improved throughput by batching the request. Instead of going to disk for every request, we batch multiple requests into disk for only one disk IO.
		- The disadvantage of this solution is by having the batch request, the system may delay the freshness because we have to wait longer to buffer up multiple requests instead of processing the requests as we see them.
	- Partition Into Multiple Serial Processing
		- Another way to increase the throughput of your system would be similar to databases, you can shard your application by a request attribute, and for each shard, you can process them serially within each shard.
		- The advantage is that you can increase the throughput by as many shards as you have since each shard can process in a mutually exclusive manner.
		- The disadvantage is the additional complexity to maintain the sharding mapping. Another potential disadvantage is sometimes the application may have a better user experience if more shards’ data are considered instead of narrowing down the search space into a single shard. If you need cross-shard consideration, there’s the overhead of cross node calls.
	- Pessimistic Locking
		- In pessimistic locking, you will need to acquire a lock to access and write to a particular resource. The lock can have different levels of granularities and can be across various entities for a given transaction. There’s a difference between a read and write lock in pessimistic locking that may be important to scale your system design question.
		- Write Lock: Also known as an exclusive lock. The holder of the write lock does not allow other transactions to write and read the resource. An exclusive lock is very safe since only one thread can access the resource at a given time. However, the trade-off is limited throughput for both read and write.
		- Read Lock: Also known as a shared lock. The holder of the read lock allows others to read but not modify the resource. Internally, it will create a local copy for other threads to read while the transaction modifies an intermediate copy. The advantage of this is an improved throughput for reads since multiple threads can read simultaneously. The problem is both read and write lock still limit the write throughput.
		- The advantage of pessimistic locking is the simplicity to reason about the correctness of the design where you need to acquire a lock before the transaction.
		- A pessimistic lock is preferable in a system design interview if the read and write queries are low and correctness is critical. The disadvantage is that in a highly concurrent environment to a given resource, the throughput can be limited since both write and read locks can block write, and a write lock can block both write and read. Also, as your application becomes more complicated, deadlocks might happen if not designed carefully. In addition, for pessimistic locking, sometimes you may be bottlenecked for a rogue thread, causing other threads to wait on the lock. In this case, you’ll need some timeout to release the lock, and the rogue thread just wasted other threads’ time.
- Scope of the Lock
	TODO
